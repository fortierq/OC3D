\documentclass[10pt,a4paper]{article}
\usepackage[latin1]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage[perpage]{footmisc}
\usepackage{bbding}

\usepackage{amsthm} % newtheorem
\newtheorem{pb}{Problem}
\newtheorem{theorem}{Theorem}
\theoremstyle{definition}
\newtheorem{defi}{Definition}
\newtheorem{lemma}{Lemma}
\theoremstyle{remark}
\newtheorem{rem}{Remark}

\renewcommand{\textbf}[1]{\begingroup\bfseries\mathversion{bold}#1\endgroup}
\newcommand{\fin}{\begin{flushright}
$\Box$
\end{flushright}}

\usepackage{hyperref}
\hypersetup{colorlinks,citecolor=red,filecolor=blue,linkcolor=blue,urlcolor=blue}

\usepackage[ruled,vlined]{algorithm2e}
\SetKwInOut{Input}{Input}\SetKwInOut{Output}{Output}

\newcommand{\V}{$\mathbb{V}$}
\newcommand{\D}[1]{$\partial$#1}
\newcommand{\C}{$\mathcal{C}$}
\renewcommand{\L}{$\gamma$}
\renewcommand{\S}{$\mathbb{S}$}
\newcommand{\Dual}{$G^*$}
\newcommand{\DualAdj}{$\overline{G^*}$}
\newcommand{\Ciz}{ciz}
\newcommand{\Sys}{$\mathcal{Y}$}
\newcommand{\PbOne}{1-MIN-CUTTING}
\newcommand{\PbTwo}{2-MIN-CUTTING}
\renewcommand{\P}{$\mathbb{P}$}
\newcommand{\K}{$\mathcal{K}$}
\newcommand{\MinC}{\C$_{min}$}
\newcommand{\N}[1]{$\mathcal{N}_{\textnormal{#1}}$}
\newcommand{\Path}{$\mathcal{P}$}
\newcommand{\Cut}[2]{\ScissorHollowRight(#1, #2)}

\author{Quentin Fortier}
\title{Graph-based models of volumetric medical data and applications to topological correction}
\begin{document}
\maketitle
%\tableofcontents
TODO: continue $->$ step, WARNING: refaire init\_pants après chaque optimisation, [precaution]
\footnotetext[0]{Univ. Blaise Pascal - LIMOS - UMR 6158
Campus Scientifique des Cézeaux, 63177 Aubière Cedex, France,
e-mail: $\lbrace$Jean-Marie.Favreau,Vincent.Barra $\rbrace$@isima.fr}
\textbf{Supervisors}: Vincent Barra\footnotemark[0] , Jean-Marie Favreau\footnotemark[0], Marco Attene\footnote{Istituto per la Matematica Applicata e le Tecnologie Informatiche, Consiglio Nazionale delle
Ricerche, Via De Marini 6, 16149 Genova, Italy, e-mail: attene@ge.imati.cnr.it}.
\begin{abstract}
After stating some results about surface cutting, this article gives an algorithm to "optimally" cut a volume, based on pants decomposition, and several variants. It introduces two new algorithms, the neighborhood algorithm and the single pant algorithm, and a C++ code named OC3D available under GPL v3, which are my main contributions. 
\end{abstract}
\section{Introduction}
The reader not familiar with basic algebraic topology will find in the appendix the definitions needed in this report.
\subsection{Overview}
The limited resolution or the noise may increase the genus of the surfaces given by medical images and
we want to remove them, both to have a more accurate image and apply algorithms that need genus 0 surfaces. \\
For that purpose, important works have been done in finding the shortest system of loops cutting reducing the genus to 0: several methods were proposed, for example in \cite{JMThese} or \cite{EricThese}. \\
The goal of this internship is to extend these methods to a volumic topological correction, in which only few works have been done. 
\subsection{Modelling}
For more precision, we first need some definitions: (all surfaces are assumed to be closed)
\begin{defi}
A \textit{volume} \V{} (resp. \textit{surface}) is a 3(resp. 2)-manifold embedded in $\mathbb{R}^3$.
We assume a volume has one boundary \D{\V} and the genus g of \V{} (i.e the genus of \D{\V}) is assumed to be different from 0.
\end{defi}
From an algorithmic point of view, instead of an abstract 3-manifold we deal with either a 3-mesh (a set of tetrahedra) or voxels, which are obviously a volume in the sense of the above definition. We refer to them as discrete volume. Discrete surfaces are either sets of triangles or of faces of a voxel set.\\
Moreover, we assume these discrete volumes or surfaces to have a weight on their faces or edges (typically, the weight is the length for an edge and the area for a face or the probability that the two volumic elements are adjacent, given by the segmentation step). 
\begin{figure}[htb]
  \begin{center}
    \includegraphics[height=2cm]{voxels.eps}
    \caption{Voxels}
  \end{center}
\end{figure}
\begin{defi}
Given a discrete volume \V, the \textit{dual graph} \Dual{} = (V, E) of \V{} is contructed the following way:
\begin{itemize}
\item The vertices of \Dual{} are the volumic elements (tetrahedra or voxels).
\item Two vertices are connected if the corresponding two elementary volumes share a face, and the weight of this edge is the weight of the face.
\end{itemize}
Two edges of \Dual{} are \textit{adjacent} if the corresponding faces share an edge of \V{}.
\end{defi}
We define similarly the dual graph of \S{}: we replace volumic elements by faces of the surface, and two vertices are connected if the corresponding faces share an edge. \\
Since every vertex in \Dual{} has a degree at most d, with d =  6 if \V{} is a voxel set and d = 4 if \V{} is a 3-mesh, 2 E = $\sum deg(v)$ $\leqslant$ d V, so O(E) = O(V) (in all this report, if A,B are sets O(A) means O($\vert$A$\vert$) and O(AB) means O($\vert$A$\vert$ $\vert$B$\vert$)).
\begin{defi}
Let A, B be two sets such that A $\subset$ B and B is connected. \\
A is B-\textit{non-separating} if B - A is connected. \\
Similarly, if $A_i$ $\subset$ B, $\lbrace A_1, \ldots, A_n \rbrace$ is B-non-separating if B - $\bigcup$ $A_i$ is connected.
\end{defi}
\begin{defi}
A \textit{1-cut} \L{} (on a surface \S{}) is a \S{}-non-separating loop.
\end{defi}
On the dual of \S, a 1-cut is a simple cycle of edges.
\begin{defi}
A \textit{2-cut} \C{} (in \V{}) is a connected, \V{}-non-separating, genus-0 surface such that \D{\C} lies on \D{\V}.
\end{defi}
On \Dual{}, a 2-cut is a set of adjacent edges (however it is not sufficient, since we require the set to be a manifold).
\begin{defi}
The \textit{cutting product} of a surface \S{} along a 1-cut \L{} (written \Cut{\S}{\L}) is, informally, the surface produced by duplicating every edge and vertex and removing the adjacences between faces sharing an edge in \L{}. \\
The informal definition is similar for a volume and a 2-cut. \\
See \cite{JMThese}, p. 35, for a more detailed definition.
\end{defi}
\begin{defi}
A \textit{system of} 2(resp. 1)-\textit{cuts} of \V{} (resp. \S) is a \V{}(resp. \S{})-non-separating set of 2(resp. 1)-cuts such that the resulting cutting product has genus 0 and every pair of cuts doesn't intersect. 
\end{defi}
We can now give the main issue of this report: 
\begin{pb} [\PbTwo]
Given a discrete volume \V, find a minimum system of 2-cuts. 
\end{pb}
We are also interested in the related problem on surface, which we investigate first:
\begin{pb} [\PbOne]
Given a discrete surface \S, find a minimum system of 1-cuts. 
\end{pb}
These minimums exist, since there are finitely many sets of g 1-cuts (resp. 2-cuts).
\subsection{NP-hardness}
An apparently similar problem is known to be NP-hard: 
\begin{pb} [\PbOne -BOUNDARY]
Given a discrete surface \S, possibly with boundary, find a minimum cutting to obtain a single topological disk (i.e the resulting cutting product must have genus 0 and no boundary).
\end{pb}
\begin{theorem}
\PbOne -BOUNDARY is NP-hard
\end{theorem}
\textit{Proof}:~~ \\
\cite{Erickson02} reduces this problem to the \textit{rectilinear Steiner tree problem} (i.e,  given n points in the plane, find a tree connecting them with only vertical and horizontal line segments), which is known to be NP-hard.
\fin
However, it is not known if \PbOne{} and \PbTwo{} are NP-hard, but the two problems are linked. \\
In the case of voxels, we have:
\begin{theorem}
\PbOne{} reduces to \PbTwo.
\end{theorem}
\textit{Proof}:~~ \\
Let \S{} be an instance of \PbOne: according to Jordan's theorem, \S{} bounds only one volume \V. \\
For each face of \V, we put a weight equals to the sum of the weights of the edges of this face that are in \S. 
This way the area of a surface in \V{} equals its perimeter. \\
The size of \V{} is polynomial in the size of \S{} according to the isoperimetric inequality: 36 $\pi$ vol(\V)$^2$ $\leqslant$ area(\S)$^3$, and since the volume of \V{} equals the number of voxels in \V and the area of \S{} equals the number of faces (squares) in \S.
\fin
The same theorem holds for tetrahedra if we restrict the problem to PLCs (\textit{Piecewise Linear Complex}) which can be tetrahedrized (not all surfaces can be tetrahedrized).
\subsection{Relations between the two problems}
Although they have similarities, the two problems above are not identicals and especially, minimizing the area of a surface is not equivalent to minimizing its perimeter. \\
Moreover, a surface with bounded area may have a perimeter equals to infinity (figure \ref{Koch}).\\
\begin{figure}[H]
\begin{center}
\begin{minipage}{0.4\linewidth}
\centering \includegraphics[height=2cm]{koch_snowflake.eps}
\end{minipage}
\hfill
\begin{minipage}{0.4\linewidth}
\centering \includegraphics[height=2cm]{torus_star.eps}
\end{minipage}
\caption{Left: The Koch snowflake, a surface with finite area but with infinite perimeter. 
Right: The optimal 1-cut (in blue) is different from the optimal 2-cut (in red) of this torus. }
\label{Koch}
\end{center}
\end{figure}
\section{Previous works on surface cutting}
In all this section, let \S{} be a surface with genus g.\\
This section introduces two algorithms dealing with \textbf{surface cutting}, the first described in \cite{JMThese}, chap. 3 and the second in \cite{EricThese}, chap. 3.\\
Both uses a similar approach to find 1-cuts: they first show that computing a 1-cut is easy if we add constraints to it and then they split the surface, to force the wanted constraints.
\subsection{Cutting a surface to reduce its genus to 0}
Using the following approach, we can get a good approximation of a minimum system of 1-cuts of \S.
\begin{lemma}
We can calculate the shortest 1-cut on \S{} passing through a fixed point p in O(Vlog(V)).
\end{lemma}
\textit{Proof}:~~ \\
We use Dijkstra's algorithm from p. As soon as we meet a vertex previously visited, we look at the number c of connected components of the complementary of the surface: if c equals one we continue our search, otherwise (c equals two) we found a shortest 1-cut from p.
\fin
\begin{lemma}
We can compute a first system of 1-cut \Sys{} on \S{} in O(V).
\end{lemma}
\textit{Proof}:~~ \\
Let t be a volumic element (triangle). We use the \textit{cut locus} associated to t, i.e the set of all points having more than one shortest path from t: we take as \Sys{} the non arborescent part of this cut locus, called the \textit{reduced} cut locus.
\fin
\begin{lemma}
Every 1-cut of \S{} crosses \Sys.
\end{lemma}
\textit{Proof}:~~ \\
If a 1-cut doesn't cross \Sys, it is included in \Cut{\S}{\Sys} which is a genus 0 surface. Every loop on such a surface is contractible so separating, a contradiction.
\fin
By calculating the shortest 1-cut passing through every triangle of \Sys, we have:
\begin{theorem}
We can compute a shortest 1-cut in O(\Sys{} Vlog(V)).
\end{theorem}
The algorithm consists in iteratively calculating the shortest 1-cut, while possible. This may not lead to the minimum system of 1-cuts.
\subsection{Shortest homotopic cycles on a surface}
This second algorithm uses \textit{n-pants} (a genus-0 surface with n boundaries, see figure \ref{3pant}). \\
\begin{figure}[htb]
  \begin{center}
    \includegraphics[height=2cm]{3pant.eps}
    \caption{A 3-pant}
    \label{3pant}
  \end{center}
\end{figure}
\begin{theorem}
In a 3-pant, we can compute the shortest 1-cut homotopic to a a boundary of the pant in O(Vlog(V)).
\end{theorem}
\textit{Proof}:~~ \\
To establish this result, we need (see proof in \cite{EricCours})
\begin{lemma}
In a cylinder, we can compute the shortest 1-cut homotopic to a boundary of the cylinder in O(Vlog(V))
\end{lemma}
We can use this lemma on a 3-pant by cutting along a shortest path from the two remaining boundaries.
\fin
\begin{lemma}
In \cite{EricLazarus}, one can find the following results:
Every compact connex orientable surface unless the sphere, disk, cylinder and torus have a 3-pants decomposition (a set of disjoint 1-cuts cutting \S{} into 3-pants).
\end{lemma}
\begin{lemma}
With such a surface, we can compute a first 3-pants decomposition \P$_0$  in O(gV).
\end{lemma}
Then we can give the pants optimization algorithm: compute a 3-pants decomposition and optimize locally every boundary of a pant, until no improvement is possible.
\cite{EricLazarus} gives an upper bound for the number of iterations of this algorithm: the (difficult) proof uses rewriting on \textit{crossing words} (words encoding crosses between curves). \\
In particular, this algorithm is polynomial in its input. \\
\cite{EricLazarus} also proves that this algorithm is optimal, in this sense: each cut in the resulting pants decomposition \P{} is the shortest cut homotopic to the initial corresponding cut in \P$_0$. However this algorithm doesn't solve \PbOne: the homotopy classes of \P{} are not, \textit{a priori}, equal to the homotopy classes of a minimum system of 1-cuts (it is worth remembering that homotopy classes can't change while optimizing, with this algorithm).
\subsection{First attempts to do a volume cutting}
A first idea, suggested before the internship, is to put volumical information on the surface.
\begin{defi}
The \textit{medial axis} (or \textit{skeleton}) of \V{} is the set of all points (not in \D{\V}) having more than one closest point to \D{\V}, i.e the centers of the open balls tangent to \D{\V} in at least two points.
\end{defi}
\begin{defi}
The \textit{local feature size} of a point on \D{\V} is its distance to the medial axis.
\end{defi}
The method consists in defining the length of an edge on \D{V} as the product of the local feature size of the adjacent vertices and the Euclidean length of this edge. It is an estimation of the area that is introduced if we select this edge in a 1-cut. Then we can use a method from the previous section to compute an approximation of the shortest system of 1-cuts on \D{V}. However this doesn't use all the volumic information and incoherent cuttings may happen.%[http://wiki.jmfavreau.info/post-doc_2009/projects/volumic_correction/report_june_2010]
\begin{figure}[H]
  \begin{center}
    \includegraphics[height=2cm]{LFS.eps}
    \caption{Length defined by the local feature size}
  \end{center}
\end{figure}
Another idea, inspired by the second above algorithm, is to decompose a volume into volumic 3-pants and to optimize them. It is the main idea of the approach described next.
\section{General algorithm}
\subsection{Overview}
The generic algorithm is the following:
\begin{itemize}
\item Compute a first volumic pants decomposition. 
\item Optimize (i.e change the location while decreasing the weight) every boundary of the cuts while possible.
\item Among the resulting pants decomposition, select a system of 2-cuts.
\end{itemize}
Two algorithms result from this pattern, which I call \textit{multi pants (MPA)} and \textit{single pant (SPA) algorithms}.
\subsection{First decomposition}
To compute a first cutting, I already described the cut locus method: given a set of points A, the \textit{A-cut locus} is the set of all points having more than one shortest path from A. \\
In the SPA, we simply choose an arbitrary point p, compute the reduced p-cut locus \Sys{} and take as an initial decomposition the n-pant which boundaries are the g connected components of \Sys. \\
However, one may try to act more \textit{locally} and to use \textit{topological information} to guide the choice of the cuts (i.e to have an initial set of cuts "close" to the optimal) by decomposing the volume into many pants.  \\
For that purpose, the MPA first compute the skeleton (or medial axis) \K{} of the surface, using for example an \textit{erosion} process (see \cite{Cornea07} for a comprehensive survey of skeleton computation).\\
\begin{figure}[H]
\begin{center}
\begin{minipage}{0.4\linewidth}
\centering \includegraphics[height=3cm]{skeleton.eps}
\end{minipage}
\hfill
\begin{minipage}{0.4\linewidth}
\centering \includegraphics[height=3cm]{cutlocus_skeleton.eps}
\end{minipage}
\caption{Left: Skeleton. 
Right: Cuts associated to this skeleton. }
\end{center}
\end{figure}
Let B be the set of all intersection points of \K: the MPA basically computes the reduced B-cut locus and uses its connected components as a pants decomposition. \\
%All the resulting pants need not have the same number of boundaries, but assuming that it is the case, we can know %precisely the number of such pants:
%\begin{theorem}
%Let p be the number of pants and c the number of cycles of any n-pants decomposition of \S{}.\\
%Then p = 2(g-1) and c = 3(g-1).
%\end{theorem}
%\textit{Proof}:~~ \\
%For one pant P, according to Euler's formula: $V_P - E_P + F_P$ = 2 - b = - 1.\\
%Since every couple of pants share a number of vertices equals to the number of edges shared, the number of pants is: %$\sum_{P ~pant} (-V_P + E_P - F_P)$ = $V - E + F$ = 2 - 2g. \\
%If we duplicate every pant we find 2c = 3g, since every cut has exactly two adjacent pants.
%\fin
However, we can have intersections in this reduced cut locus, and we are not sure to get 2-cuts: Marco Attene and
Jean-Marie Favreau suggested a method to avoid such not manifold cuts, but it is rather complicated and I didn't have the time to investigate it further. 
\subsection{Pant(s) optimization}
I first discuss how to optimize a single 2-cut, the next subsection will deal with the problem of selecting a cut to optimize. \\
We need to distinguish one kind of 2-cut:
\begin{defi}
A 2-cut \C{} is an auto 2-cut if the two pants adjacent to \C{} are actually the same pant. 
\end{defi}
Since the SPA deals with only one pant, every 2-cuts are auto, and I first describe the optimization of an auto 2-cut \C, associated to a pant \P. 
\subsubsection{Optimization of an auto 2-cut \C}
We first build the network R from \Dual{} the following way:
\begin{itemize}
\item Add two vertices s and t to \Dual{}.
\item Link s to all the vertices adjacent to \C{} on one side and the vertices adjacent to \C{} on the other side to t.
\item For each boundary \C' of \P{} delete \C', and, if \C' $\neq$ \C{}, delete the edges with an end point adjacent to \C'{}.
\end{itemize}
The second part of this last point is needed in order to avoid intersections between 2-cuts. \\
Then, we compute a max flow on R (using Ford Fulkerson algorithm, for example) and we use the min cut - max flow theorem to deduce a \textit{min \C{} s-t cut} (i.e, a min cut obtained by computing a max flow to optimize \C) \MinC.
However, \MinC{} is not necessarly a 2-cut (for example \D{\MinC} is not necessarily connected) but in most applications we hope that \MinC{} is indeed a 2-cut, and, with some [precaution] we will see after, \textbf{we assume that every min cut computed this way is a 2-cut}. \\ 
Then it is easy to see that, throughout the SPA, the pant structure is kept ((\Sys - \C) $\cup$ \MinC{} is a system of 2-cuts). \\
Moreover, the result of the SPA is likely to be, in practice, independant from the initial set of cuts. \\
However, it is possible that the best cut \C' intersects \C, and a max flow will not take it into account (both in the SPA and the MPA). \\
To avoid this problem, I suggested to take a \MinC{} s-t cut as the new cut replacing \C{} (so we do two consecutive max flows), which correctness is validated by the theorem: 
\begin{theorem}
\C' doesn't intersect \MinC. 
\end{theorem}
\textit{Proof}:~~ \\
\begin{figure}[H]
\begin{center}
\includegraphics[height=4.cm]{demoauto.eps}
\caption{Illustration of the proof by contradiction.}
\label{proofauto}
\end{center}
\end{figure}
Assume \C' intersects \MinC.  \\
Then we can find a shortest \C{} s-t cut (in green in figure \ref{proofauto}) that doesn't intersect \C{} by following \MinC, then \C'{} when \C' and \MinC{}  intersect. \\
This contradicts the fact that \MinC{} is a min \C{} s-t cut.
\fin
\subsubsection{Optimization of a 2-cut \C{} (not auto)}
\begin{figure}[H]
  \begin{center}
    \includegraphics[height=1.4cm]{mincut.eps}
    \caption{Optimization of a cut}
  \end{center}
\end{figure}
Now we assume that \C{} is adjacent to two different pants \P$_1$ and \P$_2$, let \C$_{i, j}$ be the boundaries of \P$_i$ different from \C. \\
We need to be careful since we want to avoid disconnected min cut. \\
We build R from \Dual{} the following way:
\begin{itemize}
\item Find a shortest tree $\mathcal{T}_{1}$ (resp. $\mathcal{T}_{2}$) connecting $\bigcup$ \C$_{1, j}$ (resp. $\bigcup$ \C$_{2, j}$). 
\item For all j, link s to \C$_{1, j}$ and $\mathcal{T}_{1}$ and link \C$_{2, j}$ and $\mathcal{T}_{2}$ to t.
\end{itemize}
We need to find the trees $\mathcal{T}_{i}$ to avoid disconnected min cuts. \\
This way, every \C{} s-t cut is homotopic to \C: \textbf{we don't change homotopy classes}. \\
The search of the trees is a problem known as the Steiner tree problem, which is NP complete: in pratice we may prefer to do an approximation of it (for example, in the C++ code, I compute $\mathcal{T}_{1}$ by iteratively selecting the closest cut (among the \C$_{1, j}$) adjacent to the current cut and linking them), we just want a tree that will not restrict too much the choice of the min \C{} s-t cut. \\
However, we can't avoid the restriction of the homotopy classes: if \P$_1$ and \P$_2$ have respectively n and m borders, there are (n-1)(m-1) homotopy classes unreachable during this max flow. [fig]
\subsection{Processing choice} 
Since every optimization of a 2-cut decreases the weight of the 2-cut system \Sys, and as there are only finitely many possible total weights (for a discrete volume), our algorithms are \textit{terminating}. \\
However, the final weight of \Sys{} and the complexity of these algorithms depends crucially on the order we choose cuts to optimize. \\
Several possible choices were considered:
\begin{itemize}
\item Randomly.
\item Maximum weighted 2-cut first.
\item (All-Min) I also suggested, especially in the SPA, to optimize the 2-cut \C{} which lead to the minimum possible \MinC, and to never optimize \MinC later.
\end{itemize}
Bounding the number of iteration required for the 2 first points is likely to be very difficult (personal communication with Éric Colin de Verdière). \\
However the All-Min choice requires $\Omega$(g$^2$) max flow, with the SPA: at the beginning there are g 2-cuts to optimize, so we compute g max flow, then we fix one 2-cut so we compute g - 1 max flow, and so on. \\
And indeed, g + g - 1 + $\ldots$ + 1 = $\frac{g(g+1)}{2}$ = $\Omega$(g$^2$). \\
Unfortunately it is difficult to select a "best" method: we can, for each of these methods, contruct examples such that the resulting cutting given is not the optimal and the "quality" of the resulting cutting (i.e, its weight) may depend strongly on the volume we consider, or the initial cutting. \\
The main issue is the intersections between 2-cuts: however short it may be, a min cut \MinC{} computed by max flow is not necessarly in a shortest system of 2-cuts since it may intersect a lot of other small cuts.
%Moreover, the validity of the All-Min choice is validated by:
%\begin{theorem}
%Let \C$_1$, $\ldots$, \C$_k$ be the first k 2-cuts chosen by All-Min \\
%C$_k$ is the minimum [non separating of the decoupage]2-Cut among all cuts not intersecting
%\end{theorem}
%\textit{Proof}:~~ \\
%Let ... Montrer que il existe cut tel que max flow le donne.
%\fin
\subsection{Selection of a cutting system}
When the SPA is finished, there is only one choice for the final system of 2-cuts (we must take all 2-cuts) and for the MPA we simply use the greedy choice: iteratively select the shortest 2-cut, while possible (i.e, until there are g 2-cuts selected). 
\subsection{Parallelization}
I suggested the following method to optimize simultaneously several cuts, with the MPA: compute the graph which vertices are the 2-cuts and with an edge between two vertices if the two corresponding cuts share a pant. Then find an independent set (or an approximation: finding an independent set is NP-hard) in this graph and optimize simultaneously every cut in this set. \\
This way we are sure cuts we optimize will not interfere. \\
When all these optimizations are done, compute an independent set of the remaining vertices (which were not optimized) and optimize such a set. Continue this process until there is no more cut to optimize.
\section{Neighborhood}
\subsection{The algorithm}
For simplicity, in all this section we assume that our volumes are made of voxels, unless explicitly stated. \\
%\textbf{We assume that all the capacities of the edges in \Dual{} are equal to one} (this is the case, for example, if \V{}  is a set of voxels and that we put a capacity on every edge equal to the area of the corresponding face).
The most time consuming part of both SPA and MPA being the computation of a max flow, one may try to improve its time complexity, and indeed, we can act more locally. %(for the importance of local search and neighborhood, see \cite{Papa98}). \\
The basic idea of the neighborhood algorithm is that, during Ford Fulkerson algorithm, we can select an augmenting path "near" the previous found paths, which restricts the number of edges to visit. To define precisely what the "near" means, we need a more dense graph:
\begin{defi}
The dual-adjacency graph \DualAdj{} is the graph with the same vertices as \Dual{} and with an edge (with neither a weight nor a capacity) between two vertices if the two corresponding volumic elements share at least one vertex.
\end{defi}
We need it to take into account path such as [fig].
\begin{defi}
If v is a vertex and p a set of vertices (for example, a path), d(v, p) (and d(p, v)) is the minimal length of a shortest path, in \DualAdj{}, between v and a vertex of p. \\
Given two set of vertices p and p', d(p, p') = max$_{v \in p}$ d(v, p'). \\
The p-neighborhood \N{p} is the set of all vertices v such that d(v, p) $\leqslant$ 1. 
%If \Path{} = $\lbrace p_1, \ldots, p_n \rbrace$ is a set of paths, \N{\Path} = $\Delta$ \N{$p_i$} ( = ($\bigcup$  \N{$p_i$}) -  $\bigcup p_i$), and we define similarly \Ns{\Path}.
\end{defi}
\begin{rem}
d is a distance: d(p, p') = d(p', p), d(p, p') = 0 $\Longleftrightarrow$ p = p' and d(p, p'') $\leqslant$ d(p, p') + d(p', p''). \\
Moreover, a path p' is included in \N{p} if and only if d(p, p') $\leqslant$ 1.
\end{rem}
Then, to compute a max flow, we can use the following algorithm which I call neighborhood algorithm (the algorithm keeps a growing neighborhood N where the paths are searched): 
\begin{algorithm}
\caption{Neighborhood algorithm (NA)\label{}}
Let p$_i$ be a shortest path from s to t in R (using BFS) \;
N $\leftarrow$ \N{p$_i$} \;
\While{There is an augmenting path p from s to t in R $\cap$ N}
{
	Augment flow along p \;
	N $\leftarrow$ N $\cup$ \N{p} \;
}
\end{algorithm} \\
Of course, the first path computed may visit all the reachable edges (as in the classic Ford Fulkerson), but all other paths are searched in the growing neighborhood. \\
The following theorem shows that we actually get a max flow at the end of the neighborhood algorithm:
\begin{theorem}
Assume we are computing a max flow in \V, using neighborhood algorithm and that we already found a not empty set of augmenting paths \Path. \\
Let R be the residual network, and f the current flow. \\
If there is no path from s to t in R $\cap$ \N{\Path} then f is a max flow.
\end{theorem}
\textit{Proof}:~~ \\
Assume f is not a max flow: there is at least one path p$_0$ from s to t in R. \\
$\lbrace$ d(p, \Path), p path from s to t in R $\rbrace$ is a finite, non empty (p$_0$ belongs to it) set of $\mathbb{N}$ so it has a minimum m, let p$_1$ be a path such that d(p$_1$, \Path) = m. \\
If m $\leqslant$ 1, p$_1$ $\in$ R $\cap$ \N{\Path} and the theorem is proved. \\
Otherwise, let v be a vertex in p$_1$ such that d(v, \Path) $\geqslant$ 2.\\
Since d(v, \Path) $\geqslant$ 2, \N{\Path} $\cap$ \N{v} = $\varnothing$, and every edge in \N{v} has a flow equals to 0 (i.e, these edges are in the residual graph R). \\
Let q be the path \N{v} $\cap$ p$_0$. \\
Since all paths from s to t are homotopic (such that there is no "hole" between them), we can find a path q' in \N{v} with same extremities than q and replace q by q' such that for all vertices w added this way, d(w, \Path) $<$ d(v, \Path). \\
If we do this with all such vertex v, we create a path p such that d(p, \Path) $<$ m, a contradiction. So m $\leqslant$ 1.
\fin
\subsection{Complexity}
For simplicity, we assume in this subsection that every edge has capacity 1 (it is the case, for example, if the capacity of an edge is equal to the area of the corresponding face).
\begin{theorem}
Let p be the shortest path from s to t (we assume that it is already computed with a BFS), \C{} a min s-t cut. \\
The neighborhood algorithm (without the computation of the first path) has complexity O(p\C$^2$).
\end{theorem}
\textit{Proof}:~~ \\
Throughout the algorithm, the neighborhood grows and at the end, its size is inferior to p$\vert$\C$\vert$ (the size of a complete cylinder with axis p), since the algorithm stop as soon as the min cut is found. \\ 
So we visit at most p$\vert$\C$\vert$ vertices for each BFS, and there are $\vert$\C$\vert$ such BFS.
\fin
In the case of tetrahedra, this result is false since we can have an arbitrary number of tetrahedra adjacent to a single tetrahedra (however, the algorithm may perform very well on tetrahedra, see section \ref{time}). [fig] \\
The first path p can be computed in O(min(p$^3$, V)), indeed we stop the BFS as soon as we reach t so we can't visit more than $\frac{4}{3} \pi$ p$^3$ vertices (the size of a ball with radius p). \\
Then the whole NA has complexity O(max(min(p$^3$, V), p\C$^2$)). \\
Moreover, we can give an interesting asymptotic bound given by \cite{Bollo}:
\begin{theorem}
Let r $\geqslant$ 3.\\
Almost all r-regular graph of order n has diameter less than K log(n), with K constant (informally, the probability of selecting such a graph tends to 1 as n increases).
\end{theorem}
\Dual{} is not exactly regular (every vertex has a degree \textit{inferior} to 4 (for tetrahedra) or 6 (for voxels)) since the vertices on the border of the volume have a smaller degree, but, for well-shaped volume we may expect this bound to be relevant, and we may expect p to be O(log(V)) (p is obviously shorter than the diameter). \\
Moreover, for our applications, the area of a min cut is small. 
\subsection{Variant: the Step Neighborhood Algorithm}
Instead of augmenting the neighborhood whenever a s-t path is found, it may be interesting to find path in the neighborhood while possible and to augment the neighborhood by step, only when no path is found. \\
If no path is found after we augmented the neighborhood, the algorithm stops and reports a max flow. \\
\begin{algorithm}[H]
\caption{Step neighborhood algorithm (SNA)\label{}}
Let p$_i$ be a shortest path from s to t in R (using BFS) \;
N $\leftarrow$ \N{p$_i$} \;
\While{There is an augmenting path p from s to t in R $\cap$ N}
{
	\Path $\leftarrow$ $\lbrace$p$\rbrace$ \; 
	Augment flow along p. \;
	\While{There is an augmenting path p' from s to t in R $\cap$ N}
	{
		Augment flow along p'. \;
		\Path $\leftarrow$ \Path $\cup$ p' \;
	}
	N $\leftarrow$ N $\cup$ \N{\Path} \;
}
\end{algorithm} 
The advantage of this variant is that N is more "compact", we only augment it when needed so we visit less edges. \\
It also computes sligthy longer paths than the NA and computes more BFS since every time we augment N, we do a "useless" BFS which find no path, although this BFS is performed while R $\cap$ N contains few edges so it is cheap.
\section{Implementation}
\subsection{Overview}
Initially, it was planned that I develop the optimization part of the MPA, and that the rest of the team will develop the initial pants decomposition, all in C++. \\
After two weeks working on the core algorithm, which deals with the dual graph so that it is independant from the representation (voxels or tetrahedra), I decided to use tetrahedra, although more complicated to implement than voxels, to be able to work on surfaces, with Blender \footnote{www.blender.org} for example, and use TetGen [url] to tetrahedralize them. \\ 
I also used TetMeshLib, a library to manage tetrahedral meshes that Marco Attene developed. \\
To both automatize the different tools of the algorithm and visualize more easily, I wrote a script in Blender Python API. \\
At the end of the internship, I worked together with Jean-Marie Favreau, using GitHub \footnote{The project is available at http://github.com/jmtrivial/OC3D}. \\
Globally, I wrote about 3000 lines in C++ and 500 in Python and the documentation, built with doxygen, is available at [url]. 
\subsection{SGL}
SGL (Simple Graph Library) is a graph library I started to develop few months before the internship and that I used in this internship. It relies on \textit{generic programming}: an ADT (Abstract Data Type) defines the required methods and semantic for a class and is used through template parameter. \\
For example, the class BFS (Breadth First Search) has a Graph template parameter, which must provide, among other, a class named iterator giving a way to iterate over all edges adjacent to a given vertex. \\
OC3D was designed in a similar way. 
\subsection{Data structures}
\begin{figure}[H]
\begin{center}
\includegraphics[height=2.4cm]{edges.eps}
\caption{Hierarchy of edge classes (an arrow means "inherits from")}
\end{center}
\end{figure}
Since we often need to iterate over all edges adjacent to a vertex, every graph is implemented as a adjacency list graph (\verb!Graph_List<Edge>!). \\
I use mainly three graphs: the pants graph, the dual graph \Dual{} and the dual-adjacency graph \DualAdj. \\
The pants graph is directed, while \Dual{} and \DualAdj{} are undirected, this is needed by the way the residual graph is used by the implementation of Ford Fulkerson algorithm: we access the residual capacity of an edge of \Dual{} (of type \verb!Edge_Dual!) providing the direction of the edge (i.e, the end extremity), it uses less memory and time since we manipulate only one edge pointer (this edge pointer is stored in the adjacency list of both extremities). \\
Since we  want to be able to add flow along both directions of every edge at the beginning of a max flow, every edge of \Dual{} has a reverse (in the opposite direction) and every edge has a pointer to its reverse. \\ 
An edge (i.e, a 2-Cut) of the pants graph is of type \verb!Edge_Cut!:  its extremities are the pants adjacent to the corresponding 2-Cut and it stores the list of the pointers to \verb!Edge_Dual! elements included in the 2-Cut. \\
Every \verb!Edge_Dual! in a \verb!Edge_Cut! has the same orientation, i.e their end extremities are in the same pant. \\
This is needed to know to which vertices we must link the source (or sink) before running Ford Fulkerson algorithm, or to delete the edges out of the pant we optimize (subsection \ref{orientation} explains how to orientate a cut). \\
To avoid time waste, every 2-Cut has a reverse and a pointer to it.
\subsection{Core algorithm}
\begin{figure}[H]
\begin{center}
\includegraphics[height=2.4cm]{IO.eps}
\caption{Hierarchy of IO classes.}
\end{center}
\end{figure}
To improve genericity, the algorithm first construct the dual graph (which depends on the the representation used - voxels or tetrahedra) and then works only on the dual graph. \\
For that purpose, an object is used to deal with representation-dependant operations, IO\_Base implements the required methods of such an object but the dual graph must be set manually using IO\_Base, IO\_Tet defines how to make the dual graph from tetrahedra and IO\_Voxels from voxels image. \\
IO\_Tet\_Adj also defines how to build the dual-adjacency graph.
After the dual graph is made, we can search a max flow on it with a class derived from \verb!Max_Flow!, and \verb!Cut_vertices! is a class giving a min cut from a max flow, searching for the set S of every vertices reachable from the source s and setting as the cut the set of edges connecting S and S$^c$.
\begin{figure}[H]
\begin{center}
\includegraphics[height=1.4cm]{Max_Flow_.eps}
\caption{Simplified hierarchy of max flow classes. }
\end{center}
\end{figure}

\subsection{Orientation} \label{orientation}
When we get a cut, selecting it with Blender for example, we must orientate it. \\
After discussing it with Jean-Marie Favreau and Vincent Barra, the best solution may be the following: \\
\begin{itemize}
\item Take an element of the cut (a triangle or a square, say a triangle abc), give an orientation to it, which can be viewed as a permutation $\sigma$ of its vertices.
\item For each triangle uvw adjacent to it with an edge uv, if $\sigma(u)$ = v,  defines the orientation on t according to the permutation vuw.
\item Repeat the second point replacing abc by all new triangles with an orientation, until every triangle has an orientation.
\item For each edge uv in the cut, associated to a triangle with orientation (abc), compute det(a,b,c): if it is negative, replace uv by vu. 
\end{itemize}
This algorithm is clearly linear (assuming that the number of vertices of an element of a cut is fixed).
\begin{figure}[H]
\begin{center}
\includegraphics[height=4cm]{orientation.eps}
\caption{An orientation.}
\end{center}
\end{figure}
\subsection{Pants graph} 
We assume here that every cut is orientated. \\
When we compute a first set of 2-cut (selecting them manually or with a reduced cut locus) we then want to compute the pants graph. \\
This is straightforward for the SPA (the pants graph is complete), I now focus on the MPA.\\
Let \C{} be a 2-cut such that the adjacences of one of its side S is not defined and e an edge of \C{} such that the first extremity v is in the side S. \\
My first idea was to do a BFS from v and adding to the list of adjacent cuts of \C{} every cut found by the BFS, for a total (for all cuts) of O(gV). \\
However, Jean-Marie Favreau noticed that we can have "thin" (and disconnected) pants between two cuts such that the BFS will not find every cuts adjacent to \C. After discussing it, to solve this we can do more BFS on the extremities of the edges of \C{} in S while possible and adding cuts found this way to the list of adjacences of \C{} (avoiding multiple insertion of the same cut). \\

Moreover, it may happen that, after moving a cut to optimize it, we change the adjacences: we can repeat the above search (only in the two pants in which the cut was optimized).
\subsection{Python script}
The script (which can be found together with a video describing its working at [url]) I wrote for Blender uses, with pipeline,  OC3D\_debug, a command-line debugger which can, among other, load a mesh, make the dual graph, optimize cuts step by step and output various information. \\
To avoid freezing Blender while optimizing a cut I used several threads and I had to synchronize the threads, OC3D\_debug and TetGen.
\begin{figure}[H]
\begin{center}
\includegraphics[height=2.3cm]{ex_script_.eps}
\caption{Script interface.}
\end{center}
\end{figure}
\subsection{Running time comparison} \label{time}
To compare the algorithms of max flow (the classic Ford Fulkerson, the NA and the SNA), I tested them on a slighty modified torus, with various number of vertices. \\
The examples can be found at : [url]. \\
The timing runs were performed on a Dell inspiron 1520 with Intel Core 2 Duo T7300 Processor (2.0GHz, 4MB L2 cache) and 2048 Mo memory. \\
Compilation was done with Visual C++ 2008 with all optimization flags set for maximum speed. \\
The times require by the SNA is of same order of the time required by TetGen which has  the complexity O(\S$^2$) required by Delaunay tetrahedrization (about 80 seconds for the torus which dual has a complexity 1750000), see \cite{TetGen}.

\begin{table}[h]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Complexity (edges + vertices) of the dual graph & Classic & NA & SNA \\ \hline
200K & 111s & 61s & 29s \\ \hline
900K & 1147s & 236s & 101s \\ \hline
1750K & 2975s & 318s & 158s \\ \hline
\end{tabular}
\end{center}
\label{time}
\caption{Running time in seconds of the optimization of one 2-Cut on a torus using several algorithms of max flow (K stands for 1000).}
\end{table}
I noticed an improvement of the time required by the NA (and SNA) when the quality (i.e, the radius-edge ratio of the tetrahedra) of the tetrahedrization increases, since the higher the quality, the smaller \DualAdj{} (and then the neighborhood is also small). \\
To perform tests, I used the basic option -q constraining the radius-edge ratio to be less than 2, but is also possible to constrain more the radius-edge ratio (up to 1.414 for example, see \cite{TetGen}), although this may increases the time required by TetGen. \\
However a drawback of this contrained generation is that the number of vertices of the tetrahedrization increases slighty (for example, the tetrahedrized torus of the figure \ref{optq} has about 50K edges with -q and 40K without).
\begin{figure}[H]
\begin{center}
\begin{minipage}{0.3\linewidth}
\centering \includegraphics[height=3cm]{sectionnoq.eps}
\end{minipage}
\hfill
\begin{minipage}{0.3\linewidth}
\centering \includegraphics[height=3cm]{sectionnoqzoom.eps}
\end{minipage}
\hfill
\begin{minipage}{0.3\linewidth}
\centering \includegraphics[height=3cm]{sectionq.eps}
\end{minipage}
\caption{A section of a torus. Left: without the option -q of TetGen. Middle: without -q, zoom on a border.
Right: with -q. }
\label{optq}
\end{center}
\end{figure}
The advantage of the NA and SNA increases significantly as the number of vertices of \Dual{} increases. \\
I also compared, on the dual graph with complexity 900000, the time required for a BFS at different moments of the algorithms. \\
\begin{table}[h]
\footnotesize{
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
 & \multicolumn{ 3}{c|}{SNA} & \multicolumn{ 3}{c|}{NA} & \multicolumn{ 2}{c|}{Classic} \\ \hline
Paths found & Edges in N & Total time & Avg time & Edges in N & Total time & Avg time & Total time & Avg time \\ \hline
1 & 101 (in path) & 250 & 250 & 101 (in path) & 250 & 250 & 250 & 250 \\ \hline
21 & 2452 & 41 & 1,95 & 2452 & 49 & 2,33 & 4917 & 234,14 \\ \hline
129 & 4240 & 283 & 2,19 & 5084 & 446 & 3,46 & 30140 & 233,64 \\ \hline
363 & 9428 & 1295 & 3,57 & 11282 & 2500 & 6,89 & 86221 & 237,52 \\ \hline
741 & 21822 & 5234 & 7,06 & 25930 & 10028 & 13,53 & 165232 & 222,99 \\ \hline
1735 & 44944 & 22627 & 13,04 & 50886 & 46345 & 26,71 & 364113 & 209,86 \\ \hline
2798 & 87172 & 66810 & 23,88 & 101262 & 144944 & 51,8 & 559327 & 199,9 \\ \hline
249 & 161664 & 10568 & 42,44 & 184092 & 16781 & 67,39 & 48611 & 195,22 \\ \hline
0 & 173368 & 22 & 22 & 189654 & 33 & 33 & 94 & 94 \\ \hline
\end{tabular}
\end{center}
\label{}
\caption{Detailed time comparison on a torus with 700K edges (times are without units)}
}
\end{table}

I split the execution of the algorithms in different steps defined by the increase of the neighborhood used by the SNA (thus, the SNA found 1 path before augmenting, then 21, 129 and so on). \\
Then I compared the number of edges of the neighborhood in which the paths were found, the total time during the step, and the average (shortened Avg) time of a BFS. \\
The advantage of a neighborhood decreases slighty during the algorithm, since the neighborhood increases as the number of edges visited by a BFS on the whole graph decreases (some edges have then zero capacity and disappear from the residual graph), so the algorithm is likely to be more efficient if the min cut is small (this is especially true for voxels with capacity one, since the number of iterations is directly the number of iterations of the algorithm).
I didn't have the time to test this algorithm on voxels, but for non degenerated volume, the first neighborhood will be at most eight times the length of the first path found (if the path is a straight path, there is exactly eight disjoint paths adjacent to it). \\
For that example, it means that the first neighborhood is likely to be about 800 edges instead of 2452 for tetrahedra, three times less. \\
Then I expect the neighborhood algorithm to be more efficient with voxels.
\begin{figure}[H]
\begin{center}
\includegraphics[height=6.cm]{diagram_time.eps}
\caption{Average time of a BFS with respect to the step in the SNA.}
\end{center}
\end{figure}
\subsection{Computation of the first path} \label{firstBFS}
Since I used a rather "big" min cut in the previous tests, the time required by the first BFS is rather negligible, but if the min cut is smaller it may be interesting to find a way to avoid this first BFS (for example if the min cut is such that the first 100 paths found gives a max flow, the first BFS takes a time equal to the half of the total time required by the SNA). I describe an algorithm to do this, with the SPA:
Assume we have a set of cuts \C$_1$, $\ldots$, \C$_g$ we want to optimize. \\
Before any max flow, we can compute a set of shortest paths p$_1$, $\ldots$, p$_g$ such that p$_j$ is a shortest path from one extremity of an edge of \C$_j$ to the other extremity, without intersecting any of the cuts (I call here such a path \textit{a valid path}). This can be done in O(gV). \\
Then, if we optimize a cut (say, \C$_1$) we can use p$_1$ as the first path. The max flow on \C$_1$ gives a min \C$_1$ s-t cut \MinC. \\
Clearly, p$_1$ is also a path from one extremity of an edge of \MinC{} to the other extremity, but this may not be the case for the other paths (p$_j$ may intersect \MinC{}). \\
Let j $\geqslant$ 2: if p$_j$ doesn't intersect \MinC, p$_j$ is a valid path from a side of \C$_j$ to the other side. \\
Otherwise, we replace p$_j$ by the path obtained by concatenating p$_j$ before the intersection, then p$_1$ and then the rest of p$_j$ (see figure \ref{prooffirstBFS}). This can be done in O(\MinC p$_j$) (we just need to verify the intersection and to link suitably p$_j$ and p). \\
\begin{figure}[H]
\begin{center}
\includegraphics[height=6.cm]{demofirstBFS.eps}
\caption{Illustration of the method to update a path p$_j$ (in black) to have a valid cut (in red). p$_1$ is in blue.}
\label{prooffirstBFS}
\end{center}
\end{figure}
Since we must do this for all (g-1) cuts, the complexity for "updating" all other paths is O((g-1)\MinC p$_j$), which is likely to be better than the O(V) required by a BFS. \\
However this may lead to longer paths, increasing the size of the neighborhood used for the next max flows. \\

\section{Conclusion}
Algo with good running time. \\
Utility: code will be integrated to FAST project.
\section{Appendix}
\subsection{Mathematical background}
In all this report, we consider subsets of $\mathbb{R}^3$ with the Euclidean distance and norm. [broader]
\begin{defi}
f : X $\longrightarrow$ Y is an \textit{homeomorphism} if it is a continuous bijection.
\end{defi}
\begin{defi}
X and Y are \textit{homeomorphic} if there is an homeomorphism from X to Y.
\end{defi}
\begin{defi}
TODO\\
X is a \textit{n-manifold (with boundary)} if every point of X has a neighborhood homeomorphic to the open ball $\lbrace$ x $\in$ $\mathbb{R}^3$, $\Vert$ x $\Vert$ $<$ 1 $\rbrace$ (or to $\lbrace$ x $\in$ $\mathbb{R}^3$, $\Vert$ x $\Vert$ $<$ 1 $\rbrace$)  \\
The boundaries of X is the connected components of the points homeomorphic to TODO
\end{defi}

\begin{defi}
A \textit{loop} is a continuous map \L{} : [0, 1] $\longrightarrow$ \S{} such that \L(0) = \L(1)
\end{defi}

\begin{defi}
Two continous maps f$_1$, f$_2$ : [0, 1] $\longrightarrow$ X are \textit{homotopic} if there exists H : [0, 1]$^2$ $\longrightarrow$ X continuous such that H(0, t) = f$_1$(t) and H(1, t) =  f$_2$(t), $\forall$ t $\in$ [0, 1]. \\
A loop is \textit{contractible} if it is homotopic to a point.
\end{defi}
 \begin{defi}
The genus of a surface \S{} is the maximum number of loops without intersections and such that they don't disconnect \S.
\end{defi}


\begin{footnotesize}
\begin{thebibliography}{1}
\bibitem{JMThese} J.-M. Favreau. Outils pour le pavage de surfaces. PhD thesis, Blaise Pascal university, 2009.
\bibitem{EricThese} É. Colin de Verdière. Raccourcissement de courbes et décomposition de surfaces. PhD thesis, Paris 7 university, 2003.
\bibitem{EricLazarus} É. Colin de Verdière and F. Lazarus. Optimal pants decompositions and
shortest homotopic cycles on an orientable surface. Proceedings of the 11th Symposium on Graph Drawing , 2003.
\bibitem{EricCours} É. Colin de Verdière. Algorithms for graphs on surfaces, M.P.R.I. course Master 2. 2009-2010.
\bibitem{FAST} Cortical surface mapping using topology correction, partial flattening and 3D shape context-based non-rigid registration for use in quantifying atrophy in Alzheimer's Disease. Preprint submitted to International Journal of Biomedical Imaging, March 2010.
\bibitem{Erickson02} J. Erickson, S. Har-Peledz. Optimally Cutting a Surface into a Disk. Discrete and Computational Geometry, July 2, 2002.
\bibitem{Cornea07} N. D. Cornea, D. Silver, P. Min. Curve skeleton properties, applications and algorithms. IEEE Transactions on Visualization and Computer Graphics 13 (2007), pp 530-548.
\bibitem{Papa98} C. H. Papadimitriou, K. Steiglitz. Combinatorial optimization: Algorithms and Complexity. Dover Publications, 1998.
\bibitem{TetGen} H. Si. TetGen: User's manual. 2006.
\bibitem{Bollo} B. Bollobas and W. Fernandez de la Vega. The diameter of random regular
graphs. Combinatorica 2(1982), 125-134.
\end{thebibliography}
\end{footnotesize}

\end{document}